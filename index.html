<!DOCTYPE HTML>
<html lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

	<title>Vandad Davoodnia</title>

	<meta name="author" content="Vandad Davoodnia">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
	<link rel="stylesheet" type="text/css" href="stylesheet.css">
	<style>
		img {
		  transition: transform 0.3s;
		}

		img:hover {
		  transform: scale(1.1);
		}
	</style>
</head>

<body>
<table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr style="padding:0px">
	<td style="padding:0px">
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr style="padding:0px">
			<td style="padding:2.5%;width:63%;vertical-align:middle">
				<p class="name" style="text-align: center;">
					Vandad Davoodnia
				</p>

				<p style="text-align: justify;">I am a Ph.D. candidate at <a href="https://www.aiimlab.com/">AiiM Lab</a> at
					<a href="https://www.queensu.ca/">Queen's University</a> working on pose estimation and its applications
					for smart environments and entertainment industry. Recently, I finished my internship at Ubisoft Toronto Inc.,
					where I designed, developed, and deployed a	markerless motion capture application.
				</p>

				<p style="text-align: justify;">
					Prior to my Ph.D., I worked as a neuroscience research scientist at Brain Engineering
					Research Center (<a href="https://ipm.ir/ipmic.jsp">IPM</a>) while
					completing my B.Sc. degree from Sharif University of Technology, Iran.
				</p>


				<p style="text-align: justify;color: red">
					I am open for on the job market for industrial, research, and development roles.
					Please do not hesitate to contact me!
				</p>


				<p style="text-align:center">
					<a href="mailto:vandad.davoodnia@gmail.com">Email</a> &nbsp;/&nbsp;
					<a href="data/Vandad_Davoodnia_CV.pdf">CV</a> &nbsp;/&nbsp;
					<!--                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;-->
					<a href="https://scholar.google.com/citations?user=beBqHPMAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
					<!--                  <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp;-->
					<a href="https://www.linkedin.com/in/vandad-davoodnia/">LinkedIn</a>
				</p>
			</td>
			<td style="padding:2.5%;width:40%;max-width:40%">
				<a href="images/VandadDavoodnia.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/VandadDavoodnia.jpeg" class="hoverZoomLink"></a>
			</td>
		</tr>
		</tbody></table>



		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
			<td style="padding:20px;width:100%;vertical-align:middle">
				<h2>News</h2>
				<ul id="news-section" style="list-style-type:disc; text-align: left;border: none;">
					<!-- Each news item is a list item -->
<!--					<li>[Oct 23] Our paper got accepted in the <strong>NeurIPS 2023 M3L Workshop</strong> 2023</li>-->
<!--					<li>[Oct 23] I presented our work at <strong>ICIP</strong> 2023 in Malaysia</li>-->
<!--					<li>[Jun 23] Our work got accepted in <strong>ICIP</strong> 2023</li>-->
<!--					<li>[Feb 23] Our paper is published in <strong>Multimedia Tools and Applications</strong></li>-->
<!--					<li>[Jan 22] Our paper got accepted in <strong>ICASSP</strong> 2023</li>-->
					<!-- More news items -->
				</ul>
			</td>
		</tr>
		</tbody></table>


		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
			<td style="padding:20px;width:100%;vertical-align:middle">
				<h2>Research</h2>
				<p>
					I'm interested in computer vision, deep learning, generative AI, and virtual worlds.
					My most recent research is on modeling virtual humans using cameras.
				</p>
			</td>
		</tr>
		</tbody></table>



		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/upose3d.jpg"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.48550/arXiv.2404.14634">-->
					<papertitle>UPose3D: uncertainty-aware 3D human pose estimation with cross-view and temporal cues</papertitle>
<!--				</a>-->
				<br>
					<strong>Vandad Davoodnia</strong>,
					<a href="https://saeed1262.github.io/">Saeed Ghorbani</a>,
					<a href="https://macarbonneau.github.io/">Marc-André Carbonneau</a>,
					Alexandre Messier,
					<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>
				<br>
					<em>arXiv</em>, 2024
				<br>
				<a href="https://doi.org/10.48550/arXiv.2404.14634">[Paper]</a> <a href="https://vandaddavoodnia.github.io/upose3d">[Project]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We present an uncertainty-aware 3D pose estimation method through maximizing the likelihood of 3D
					keypoints based on the differentiable distributions of multi-view 2D keypoints.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/skelformer.jpg"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.48550/arXiv.2404.14634">-->
					<papertitle>SkelFormer: markerless 3D pose and shape estimation using skeletal transformers</papertitle>
<!--				</a>-->
				<br>
					<strong>Vandad Davoodnia</strong>,
					<a href="https://saeed1262.github.io/">Saeed Ghorbani</a>,
					Alexandre Messier,
					<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>
				<br>
					<em>arXiv</em>, 2024
				<br>
				<a href="https://doi.org/10.48550/arXiv.2404.14634">[Paper]</a> <a href="https://vandaddavoodnia.github.io/skelformer">[Project]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We present SkelFormer, an inverse-kinematic regression framework for estimating human pose and shape from videos.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/FabriCar.png"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.1145/3563657.3595988">-->
					<papertitle>FabriCar: enriching the user experience of in-car media interactions with ubiquitous vehicle interiors using e-textile sensors</papertitle>
<!--				</a>-->
				<br>
					Pouya M Khorsandi,\
					<a href="https://leejones.ca/">Lee Jones</a>,
					<strong>Vandad Davoodnia</strong>,
					Timothy J Lampen,
					Aliya Conrad,
					<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>,
					Sara Nabil
				<br>
					<em>ACM Designing Interactive Systems Conference (DIS)</em>, 2023
				<br>
				<a href="https://doi.org/10.1145/3563657.3595988">[Paper]</a> <a href="https://leejones.ca/s/dis23-30-compressed.pdf">[PDF]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We investigate the use of e-textiles in cars to reduce driver distraction when performing non-driving tasks like media playback.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/icassp_transformer.jpg"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.48550/arXiv.2303.05691">-->
					<papertitle>Human pose estimation from ambiguous pressure recordings with spatio-temporal masked transformers</papertitle>
<!--				</a>-->
				<br>
					<strong>Vandad Davoodnia</strong>,
					<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>
				<br>
					<em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2023
				<br>
				<a href="https://doi.org/10.48550/arXiv.2303.05691">[Paper]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We propose a temporal variation of the ViTs for pose estimation and pre-train it using a masked
					auto-encoder framework.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/pressure_bmi.jpg"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.48550/arXiv.2006.10453">-->
					<papertitle>Deep multitask learning for pervasive BMI estimation and identity recognition in smart beds</papertitle>
<!--				</a>-->
				<br>
					<strong>Vandad Davoodnia</strong>,
					Monet Slinowsky,
					<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>
				<br>
					<em> Journal of Ambient Intelligence and Humanized Computing</em>, 2020
				<br>
				<a href="https://doi.org/10.48550/arXiv.2006.10453">[Paper]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We use neural networks for BMI estimation and user identification from in-bed pressure sensors.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/parse.jpg"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.48550/arXiv.2202.05400">-->
					<papertitle>Parse: Pairwise alignment of representations in semi-supervised eeg learning for emotion recognition</papertitle>
<!--				</a>-->
				<br>
					<a href="https://www.guangyizhang.com/">Guangyi Zhang</a>,
					<strong>Vandad Davoodnia</strong>,
					<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>
				<br>
					<em>IEEE Transactions on Affective Computing</em>, 2022
				<br>
				<a href="https://doi.org/10.48550/arXiv.2202.05400">[Paper]</a> <a href="https://github.com/guangyizhangbci/PARSE">[Code]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We present PARSE for understanding emotions from EEG data when limited labeled data is available.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/polishnetU.jpg"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.48550/arXiv.2206.06518">-->
					<papertitle>Estimating pose from pressure data for smart beds with deep image-based pose estimators</papertitle>
<!--				</a>-->
				<br>
				<paperauthor>
					<strong>Vandad Davoodnia</strong>,
					<a href="https://saeed1262.github.io/">Saeed Ghorbani</a>,
					<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>
				</paperauthor>
				<br>
					<em>Journal of Applied Intelligence</em>, 2021
				<br>
				<a href="https://doi.org/10.48550/arXiv.2206.06518">[Paper]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We present a domain adaptation method to improve body pose detection from pressure data.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/pressure_icassp.jpg"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.48550/arXiv.1908.08919">-->
					<papertitle>In-bed pressure-based pose estimation using image space representation learning</papertitle>
<!--				</a>-->
				<br>
					<strong>Vandad Davoodnia</strong>,
					<a href="https://saeed1262.github.io/">Saeed Ghorbani</a>,
					<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>
				<br>
					<em>IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2021
				<br>
				<a href="https://doi.org/10.48550/arXiv.1908.08919">[Paper]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We address the problems of using standard pose estimation models on pressure maps by
					transforming unclear pressure maps into a format resembling human figures on normal images.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/cancer.jpg"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.1109/ICMLA.2019.00077">-->
					<papertitle>Computer-aided diagnosis using class-weighted deep neural network</papertitle>
<!--				</a>-->
				<br>
					<a href="https://pritamsarkar.com/">Pritam Sarkar</a>,
					<strong>Vandad Davoodnia</strong>,
					<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>
				<br>
					<em>IEEE International Conference On Machine Learning And Applications (ICMLA)</em>, 2019
				<br>
				<a href="https://doi.org/10.1109/ICMLA.2019.00077">[Paper]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We present a deep learning method for diagnosing breast cancer tumors from medical images.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/recursive_bilstm.jpg" alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://github.com/guangyizhangbci/A-Novel-Recursive-Network-for-Irony-Detection-in-Tweets/blob/main/doc/project_report.pdf">-->
					<papertitle>A novel recursive network for irony detection in tweets</papertitle>
<!--				</a>-->
				<br>
					<a href="https://www.linkedin.com/in/arthur-araujoo">Arthur Cruz de Araujo</a>
					<strong>Vandad Davoodnia</strong>,
					<a href="https://www.guangyizhang.com/">Guangyi Zhang</a>,
					<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>,
					<a href="https://www.xiaodanzhu.com/">Xiaodan Zhu</a>
				<br>
					<em>Course Report</em>, 2019
				<br>
				<a href="https://github.com/guangyizhangbci/A-Novel-Recursive-Network-for-Irony-Detection-in-Tweets/blob/main/doc/project_report.pdf">[Paper]</a>
				<a href="https://github.com/guangyizhangbci/A-Novel-Recursive-Network-for-Irony-Detection-in-Tweets">[Code]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We present a recursive attention-based Bi-LSTM neural network for
					irony detection in tweets.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/eeg_movement.jpg"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.48550/arXiv.1908.02252">-->
					<papertitle>Classification of hand movements from EEG using a deep attention-based LSTM network</papertitle>
<!--				</a>-->
				<br>
				<a href="https://www.guangyizhang.com/">Guangyi Zhang</a>,
				<strong>Vandad Davoodnia</strong>,
				<a href="https://arsm.github.io/">Alireza Sepas-Moghaddam</a>,
				Yaoxue Zhang,
				<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>
				<br>
					<em>IEEE Sensors Journal</em>, 2020
				<br>
				<a href="https://doi.org/10.48550/arXiv.1908.02252">[Paper]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We present a left and right hand movements classification method from EEG signals using
					LSTM network with added attention mechanism.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/smc2019.png"  alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.48550/arXiv.2104.02159">-->
					<papertitle>Identity and posture recognition in smart beds with deep multitask learning</papertitle>
<!--				</a>-->
				<br>
				<strong>Vandad Davoodnia</strong>,
				<a href="https://www.aiimlab.com/ali-etemad/">Ali Etemad</a>
				<br>
					<em>IEEE International Conference on Systems, Man and Cybernetics (SMC)</em>, 2019
				<br>
				<a href="https://doi.org/10.48550/arXiv.2104.02159">[Paper]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We introduce a deep learning model that uses pressure sensor arrays to accurately identify
					a person and their sleep posture.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/anfis.jpg" alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.1016/j.fuel.2019.04.169">-->
					<papertitle>Prognostication of lignocellulosic biomass pyrolysis behavior using ANFIS model tuned by PSO algorithm</papertitle>
<!--				</a>-->
				<br>
					Mortaza Aghbashlo, Meisam Tabatabaei, Mohammad Hossein Nadian, <strong>Vandad Davoodnia</strong>, Salman Soltanian
				<br>
					<em>Fuel</em>, 2019
				<br>
				<a href="https://doi.org/10.1016/j.fuel.2019.04.169">[Paper]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We developed an Adaptive Network-based Fuzzy Inference System (ANFIS) model to estimate biomass
					pyrolysis behavior and trained it using	Particle Swarm Optimization (PSO).
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/fractals.png" alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://doi.org/10.1016/j.jneumeth.2018.10.039">-->
					<papertitle>Multifractal detrended fluctuation analysis of continuous neural time series in primate visual cortex</papertitle>
<!--				</a>-->
				<br>
				Zahra Fayyaz, Mohammadreza Bahadorian, Jafar Doostmohammadi, <strong>Vandad Davoodnia</strong>, Sajad Khodadadian, Reza Lashgari
				<br>
					<em>Journal of Neuroscience Methods</em>, 2019
				<br>
				<a href="https://doi.org/10.1016/j.jneumeth.2018.10.039">[Paper]</a> <!-- Replace with actual GitHub repo link -->
				<p style="font-size:small" align="justify">
					We demonstrated a new method for response tuning of neural activity time-series.
				</p>
			</td>
		</tr>


		<tr class="paper-info">
			<td style="padding:20px;width:25%;vertical-align:middle">
				<img src="images/eye_speed.webp" alt="clean-usnob" class="center" height="160" width="240" style="object-fit:contain">
			</td>
			<td width="75%" valign="middle">
<!--				<a href="https://arxiv.org/abs/2306.15117">-->
					<papertitle>Effect of age and glaucoma on the detection of darks and lights</papertitle>
<!--				</a>-->
				<br>
				Linxi Zhao, Caroline Sendek, <strong>Vandad Davoodnia</strong>, Reza Lashgari, Mitchell W Dul, Qasim Zaidi, Jose-Manuel Alonso
				<br>
					<em>Investigative Ophthalmology & Visual Science (IOVS)</em>, 2015
				<br>
				<a href="https://doi.org/10.1167/iovs.15-16753">[Paper]</a> <!-- Replace with actual GitHub repo link -->
				<a href="https://apps.apple.com/ca/app/eye-speed/id1033931375">[iOS]</a>
				<a href="https://apkpure.com/eye-speed/vandad.testtrial">[Android]</a>
				<p style="font-size:small" align="justify">
					We developed an iOS and Android App to study the effect of age and glaucoma on
					response time to light and dark targets.
				</p>
			</td>
		</tr>


		<!--    <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">-->
		<!--      <td style="padding:20px;width:25%;vertical-align:middle">-->
		<!--        <div class="one">-->
		<!--          <div class="two" id='smerf_image'><video  width=100% muted autoplay loop>-->
		<!--          <source src="images/smerf.mp4" type="video/mp4">-->
		<!--          Your browser does not support the video tag.-->
		<!--          </video></div>-->
		<!--          <img src='images/smerf.jpg' width=100%>-->
		<!--        </div>-->
		<!--        <script type="text/javascript">-->
		<!--          function smerf_start() {-->
		<!--            document.getElementById('smerf_image').style.opacity = "1";-->
		<!--          }-->

		<!--          function smerf_stop() {-->
		<!--            document.getElementById('smerf_image').style.opacity = "0";-->
		<!--          }-->
		<!--          smerf_stop()-->
		<!--        </script>-->
		<!--      </td>-->
		<!--      <td style="padding:20px;width:75%;vertical-align:middle">-->
		<!--        <a href="https://smerf-3d.github.io/">-->
		<!--          <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</span>-->
		<!--        </a>-->
		<!--        <br>-->
		<!--		<a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth*</a>,-->
		<!--		<a href="https://phogzone.com/">Peter Hedman*</a>,-->
		<!--		<a href="https://creiser.github.io/">Christian Reiser</a>,-->
		<!--		<a href="">Peter Zhizhin</a>,-->
		<!--		<a href="">Jean-François Thibert</a>,-->
		<!--        <a href="https://lucic.ai/">Mario Lučić</a>,-->
		<!--        <a href="https://szeliski.org/">Richard Szeliski</a>,-->
		<!--		<strong>Jonathan T. Barron</strong>-->
		<!--        <br>-->
		<!--        <em>arXiv</em>, 2023-->
		<!--        <br>-->
		<!--        <a href="https://smerf-3d.github.io/">project page</a>-->
		<!--        /-->
		<!--        <a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a>-->
		<!--        /-->
		<!--        <a href="https://arxiv.org/abs/2312.07541">arXiv</a>-->
		<!--        <p></p>-->
		<!--        <p>-->
		<!--        Distilling  a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops and smartphones at 60 FPS.-->
		<!--        </p>-->
		<!--      </td>-->
		<!--    </tr>-->




		</tbody></table>
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
			<td style="padding:0px">
				<br>
				<p style="text-align:center;font-size:x-small;">
					Design and source code from
					<a href="https://github.com/jonbarron/website" style="font-size:x-small;">Jon Barron's website</a>.
				</p>
			</td>
		</tr>
		</tbody></table>



	</td>
</tr>
</table>


<script>
	document.addEventListener("DOMContentLoaded", function () {
		const paperInfoElements = document.querySelectorAll(".paper-info");

		const observer = new IntersectionObserver(
				(entries) => {
					entries.forEach((entry) => {
						if (entry.isIntersecting) {
							entry.target.classList.add("visible");
						} else {
							entry.target.classList.remove("visible");
						}
					});
				},
				{
					rootMargin: "0px 0px -20% 0px",
					threshold: 0,
				}
		);

		paperInfoElements.forEach((element) => {
			observer.observe(element);
		});
	});
</script>


</body>
</html>
